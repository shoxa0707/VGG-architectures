{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bcdb59fc-96f1-461f-b360-8e5fccee666b",
   "metadata": {},
   "source": [
    "## Import architectures and necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe1a17c9-3e36-40a0-bba3-cbbca0fcc758",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-04 18:12:48.900067: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-04 18:12:49.473659: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import tensorflow_datasets as tfds\n",
    "from vgg16 import VGG16\n",
    "from vgg19 import VGG19\n",
    "from glob import glob\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8966c9ee-b275-433d-b617-ce6b9b99f417",
   "metadata": {},
   "source": [
    "## Preprocessing images for train model(Imagenet2012 validation dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9f5da5-3258-4191-b94c-796a032a0cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "images = []\n",
    "\n",
    "imagesfiles = [i for i in glob('data/*.JPEG')]\n",
    "for i in imagesfiles:\n",
    "    image = cv2.imread(i)/255.0\n",
    "    image = cv2.resize(image, (224,224))\n",
    "    images.append(image)\n",
    "images = np.array(images)\n",
    "\n",
    "with open('data/imagenet_2012_validation_synset_labels.txt') as f:\n",
    "    labelstxt = f.read().split('\\n')[:-1]\n",
    "with open('data/labels.txt') as f:\n",
    "    labs = f.read()\n",
    "    \n",
    "for i in labelstxt:\n",
    "    bosh = labs.find(i)\n",
    "    labels.append(int(labs[bosh+10:bosh+10+labs[bosh+10:].find(' ')])-1)\n",
    "    \n",
    "images = np.array(images)\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c9a06c4f-1d7a-44d9-954d-ebe11171ab20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40000, 224, 224, 3) (40000,)\n",
      "(10000, 224, 224, 3) (10000,)\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=100)\n",
    "print(x_train.shape, y_train.shape)\n",
    "print(x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "15aeb4c6-479c-4ccb-9276-0a2393ddade6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(keras.utils.Sequence):\n",
    "    def __init__(self, x_set, y_set, batch_size):\n",
    "        self.x, self.y = x_set, y_set\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.x) / float(self.batch_size)))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_x = self.x[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        batch_y = self.y[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        return batch_x, batch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "82218837-7091-4a82-9005-570c0aa3c705",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = DataGenerator(x_train, y_train, 32)\n",
    "test_gen = DataGenerator(x_test, y_test, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d935c62-7a44-48bc-bf55-40f7a5e49580",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-04 16:35:37.053531: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-04 16:35:37.053748: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-04 16:35:37.078500: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1956] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "class Model(keras.models.Model):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.base_model = VGG19()\n",
    "    def call(self, x):\n",
    "        x = self.base_model(x)\n",
    "        return x\n",
    "    \n",
    "model = Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "58feee90-a593-4bd3-93e9-9d3ff53cee8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n",
    "\n",
    "test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
    "test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='test_accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "75a99a9f-ae86-4982-820e-f3ee50ed982b",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(images, labels):\n",
    "    with tf.GradientTape() as tape:\n",
    "        # training=True is only needed if there are layers with different\n",
    "        # behavior during training versus inference (e.g. Dropout).\n",
    "        predictions = model(images, training=True)\n",
    "        loss = loss_object(labels, predictions)\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "    train_loss(loss)\n",
    "    train_accuracy(labels, predictions)\n",
    "\n",
    "@tf.function\n",
    "def test_step(images, labels):\n",
    "    # training=False is only needed if there are layers with different\n",
    "    # behavior during training versus inference (e.g. Dropout).\n",
    "    predictions = model(images, training=False)\n",
    "    t_loss = loss_object(labels, predictions)\n",
    "    \n",
    "    test_loss(t_loss)\n",
    "    test_accuracy(labels, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ceb062-10b5-405b-a788-3acc8492a198",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/airi/anaconda3/lib/python3.9/site-packages/keras/backend.py:5612: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 6.907754898071289, Accuracy: 0.07000000029802322%, Test Loss: 6.907752513885498, Test Accuracy: 0.10999999940395355%\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # Reset the metrics at the start of the next epoch\n",
    "    train_loss.reset_states()\n",
    "    train_accuracy.reset_states()\n",
    "    test_loss.reset_states()\n",
    "    test_accuracy.reset_states()\n",
    "\n",
    "    for train_images, train_labels in train_gen:\n",
    "        train_step(train_images, train_labels)\n",
    "\n",
    "    for test_images, test_labels in test_gen:\n",
    "        test_step(test_images, test_labels)\n",
    "    if epoch % 1 == 0:\n",
    "        print(\n",
    "          f'Epoch {epoch}, '\n",
    "          f'Loss: {train_loss.result()}, '\n",
    "          f'Accuracy: {train_accuracy.result() * 100}%, '\n",
    "          f'Test Loss: {test_loss.result()}, '\n",
    "          f'Test Accuracy: {test_accuracy.result() * 100}%'\n",
    "      )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c364a1d5-5dcf-4bec-aa99-0d2f00a026c1",
   "metadata": {},
   "source": [
    "## Finetune architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bb7f061b-8835-4d2f-9673-fef7b509e214",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-04 18:43:58.228796: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_4' with dtype int64 and shape [4]\n",
      "\t [[{{node Placeholder/_4}}]]\n",
      "2023-05-04 18:43:58.229079: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_4' with dtype int64 and shape [4]\n",
      "\t [[{{node Placeholder/_4}}]]\n",
      "Corrupt JPEG data: 240 extraneous bytes before marker 0xd9\n",
      "Corrupt JPEG data: premature end of data segment\n",
      "2023-05-04 18:43:59.893363: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype string and shape [4]\n",
      "\t [[{{node Placeholder/_1}}]]\n",
      "2023-05-04 18:43:59.893644: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_2' with dtype string and shape [4]\n",
      "\t [[{{node Placeholder/_2}}]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((3680, 224, 224, 3),\n",
       " (3680,),\n",
       " (3680, 1),\n",
       " (3669, 224, 224, 3),\n",
       " (3669,),\n",
       " (3669, 1))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = tfds.load('oxford_iiit_pet', split='train')\n",
    "test = tfds.load('oxford_iiit_pet', split='test')\n",
    "# valid = tfds.load('lfw', split='validation')\n",
    "\n",
    "x_train, y_train, y_train2, x_test, y_test, y_test2 = [], [], [], [], [], []\n",
    "for i in train:\n",
    "    a = i['image'].numpy()\n",
    "    x_train.append(cv2.resize(a, (224, 224))/255.0)\n",
    "    y_train.append(i['label'].numpy())\n",
    "    y_train2.append(i['species'].numpy())\n",
    "    \n",
    "for i in test:\n",
    "    a = i['image'].numpy()\n",
    "    x_test.append(cv2.resize(a, (224, 224))/255.0)\n",
    "    y_test.append(i['label'].numpy())\n",
    "    y_test2.append(i['species'].numpy())\n",
    "    \n",
    "x_train = np.array(x_train)\n",
    "y_train = np.array(y_train)\n",
    "y_train2 = np.array(y_train2)\n",
    "y_train2 = np.expand_dims(y_train2, axis=1)\n",
    "\n",
    "x_test = np.array(x_test)\n",
    "y_test = np.array(y_test)\n",
    "y_test2 = np.array(y_test2)\n",
    "y_test2 = np.expand_dims(y_test2, axis=1)\n",
    "\n",
    "x_train.shape, y_train.shape, y_train2.shape, x_test.shape, y_test.shape, y_test2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c9a997ef-a96d-4992-be11-ae81330f873d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# classification for two classes\n",
    "class Model1(keras.models.Model):\n",
    "    def __init__(self):\n",
    "        super(Model1, self).__init__()\n",
    "        self.base_model = VGG19(include_top=False)\n",
    "        self.flatten = keras.layers.Flatten()\n",
    "        self.fc1 = keras.layers.Dense(1000, activation='relu')\n",
    "        self.fc2 = keras.layers.Dense(256, activation='relu')\n",
    "        self.out = keras.layers.Dense(1, activation='sigmoid')\n",
    "        \n",
    "    def call(self, x):\n",
    "        x = self.base_model(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.out(x)\n",
    "        return x\n",
    "    \n",
    "# classification for 37 classes\n",
    "class Model2(keras.models.Model):\n",
    "    def __init__(self):\n",
    "        super(Model2, self).__init__()\n",
    "        self.base_model = VGG19(include_top=False)\n",
    "        self.flatten = keras.layers.Flatten()\n",
    "        self.fc1 = keras.layers.Dense(1000, activation='relu')\n",
    "        self.fc2 = keras.layers.Dense(256, activation='relu')\n",
    "        self.out = keras.layers.Dense(37, activation='softmax')\n",
    "        \n",
    "    def call(self, x):\n",
    "        x = self.base_model(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.out(x)\n",
    "        return x\n",
    "    \n",
    "model1 = Model1()\n",
    "model2 = Model2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "080e2ee9-3699-4fd0-a5e9-ed33e74b62cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss and optimizer\n",
    "loss_object1 = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "optimizer1 = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "train_loss1 = tf.keras.metrics.Mean(name='train_loss1')\n",
    "train_accuracy1 = tf.keras.metrics.BinaryAccuracy(name='train_accuracy1')\n",
    "\n",
    "test_loss1 = tf.keras.metrics.Mean(name='test_loss1')\n",
    "test_accuracy1 = tf.keras.metrics.BinaryAccuracy(name='test_accuracy1')\n",
    "\n",
    "# optimize functions\n",
    "@tf.function\n",
    "def train_step1(images, labels):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model1(images, training=True)\n",
    "        loss = loss_object1(labels, predictions)\n",
    "    gradients = tape.gradient(loss, model1.trainable_variables)\n",
    "    optimizer1.apply_gradients(zip(gradients, model1.trainable_variables))\n",
    "\n",
    "    train_loss1(loss)\n",
    "    train_accuracy1(labels, predictions)\n",
    "\n",
    "@tf.function\n",
    "def test_step1(images, labels):\n",
    "    predictions = model1(images, training=False)\n",
    "    t_loss = loss_object1(labels, predictions)\n",
    "    \n",
    "    test_loss1(t_loss)\n",
    "    test_accuracy1(labels, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "412a3932-dfcc-4e86-855a-30e128141b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss and optimizer\n",
    "loss_object2 = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "optimizer2 = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "train_loss2 = tf.keras.metrics.Mean(name='train_loss2')\n",
    "train_accuracy2 = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy2')\n",
    "\n",
    "test_loss2 = tf.keras.metrics.Mean(name='test_loss2')\n",
    "test_accuracy2 = tf.keras.metrics.SparseCategoricalAccuracy(name='test_accuracy2')\n",
    "\n",
    "# optimize functions\n",
    "@tf.function\n",
    "def train_step2(images, labels):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model2(images, training=True)\n",
    "        loss = loss_object2(labels, predictions)\n",
    "    gradients = tape.gradient(loss, model2.trainable_variables)\n",
    "    optimizer2.apply_gradients(zip(gradients, model2.trainable_variables))\n",
    "\n",
    "    train_loss2(loss)\n",
    "    train_accuracy2(labels, predictions)\n",
    "\n",
    "@tf.function\n",
    "def test_step2(images, labels):\n",
    "    predictions = model2(images, training=False)\n",
    "    t_loss = loss_object2(labels, predictions)\n",
    "    \n",
    "    test_loss2(t_loss)\n",
    "    test_accuracy2(labels, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "399c7ae2-54c0-40b3-bbe4-d157a55a073a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for 2 classes\n",
    "train_gen1 = DataGenerator(x_train, y_train2, 32)\n",
    "test_gen1 = DataGenerator(x_test, y_test2, 32)\n",
    "\n",
    "# for 37 classes\n",
    "train_gen2 = DataGenerator(x_train, y_train, 32)\n",
    "test_gen2 = DataGenerator(x_test, y_test, 32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "138ed02d-2aec-4fbe-b913-915b92d655bc",
   "metadata": {},
   "source": [
    "### Train 2 classes model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "450db126-8963-41fc-8f18-f12eeb201420",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.630222499370575, Accuracy: 67.4456558227539%, Test Loss: 0.6200920343399048, Test Accuracy: 67.75688171386719%\n",
      "Epoch 1, Loss: 0.6221380233764648, Accuracy: 67.71739196777344%, Test Loss: 0.6139532327651978, Test Accuracy: 67.75688171386719%\n",
      "Epoch 2, Loss: 0.6167575716972351, Accuracy: 67.71739196777344%, Test Loss: 0.6081777811050415, Test Accuracy: 67.75688171386719%\n",
      "Epoch 3, Loss: 0.6101758480072021, Accuracy: 67.71739196777344%, Test Loss: 0.5999705195426941, Test Accuracy: 67.75688171386719%\n",
      "Epoch 4, Loss: 0.5998147130012512, Accuracy: 67.63587188720703%, Test Loss: 0.5859784483909607, Test Accuracy: 67.75688171386719%\n",
      "Epoch 5, Loss: 0.5841957926750183, Accuracy: 68.23369598388672%, Test Loss: 0.5737913846969604, Test Accuracy: 68.43827056884766%\n",
      "Epoch 6, Loss: 0.569035530090332, Accuracy: 69.4565200805664%, Test Loss: 0.5539213418960571, Test Accuracy: 71.13655090332031%\n",
      "Epoch 7, Loss: 0.5535606145858765, Accuracy: 71.08695220947266%, Test Loss: 0.5452743172645569, Test Accuracy: 73.23521423339844%\n",
      "Epoch 8, Loss: 0.5378577709197998, Accuracy: 72.09239196777344%, Test Loss: 0.5373557209968567, Test Accuracy: 73.91659545898438%\n",
      "Epoch 9, Loss: 0.5264697670936584, Accuracy: 72.82608795166016%, Test Loss: 0.5315164923667908, Test Accuracy: 73.97110748291016%\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # Reset the metrics at the start of the next epoch\n",
    "    train_loss1.reset_states()\n",
    "    train_accuracy1.reset_states()\n",
    "    test_loss1.reset_states()\n",
    "    test_accuracy1.reset_states()\n",
    "\n",
    "    for train_images, train_labels in train_gen1:\n",
    "        train_step1(train_images, train_labels)\n",
    "\n",
    "    for test_images, test_labels in test_gen1:\n",
    "        test_step1(test_images, test_labels)\n",
    "    if epoch % 1 == 0:\n",
    "        print(\n",
    "          f'Epoch {epoch}, '\n",
    "          f'Loss: {train_loss1.result()}, '\n",
    "          f'Accuracy: {train_accuracy1.result() * 100}%, '\n",
    "          f'Test Loss: {test_loss1.result()}, '\n",
    "          f'Test Accuracy: {test_accuracy1.result() * 100}%'\n",
    "      )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e3bf23-46a0-47bf-8f3b-7ecdefd0a7e9",
   "metadata": {},
   "source": [
    "### Train 37 classes model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a213c2de-7ed6-4e28-9815-f6be366fecff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/airi/anaconda3/lib/python3.9/site-packages/keras/backend.py:5612: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 3.612581729888916, Accuracy: 2.2282607555389404%, Test Loss: 3.610687017440796, Test Accuracy: 2.7255382537841797%\n",
      "Epoch 1, Loss: 3.609954595565796, Accuracy: 3.04347825050354%, Test Loss: 3.6032521724700928, Test Accuracy: 3.2706458568573%\n",
      "Epoch 2, Loss: 3.5751006603240967, Accuracy: 4.1032609939575195%, Test Loss: 3.530716896057129, Test Accuracy: 4.715181350708008%\n",
      "Epoch 3, Loss: 3.492347478866577, Accuracy: 4.67391300201416%, Test Loss: 3.480903148651123, Test Accuracy: 5.0695013999938965%\n",
      "Epoch 4, Loss: 3.4601118564605713, Accuracy: 4.918478488922119%, Test Loss: 3.4681153297424316, Test Accuracy: 5.396565914154053%\n",
      "Epoch 5, Loss: 3.4473304748535156, Accuracy: 5.1902174949646%, Test Loss: 3.463289499282837, Test Accuracy: 5.696374893188477%\n",
      "Epoch 6, Loss: 3.4391191005706787, Accuracy: 5.2717390060424805%, Test Loss: 3.46030855178833, Test Accuracy: 5.532842636108398%\n",
      "Epoch 7, Loss: 3.43288516998291, Accuracy: 5.5163044929504395%, Test Loss: 3.457617998123169, Test Accuracy: 5.505587577819824%\n",
      "Epoch 8, Loss: 3.427492141723633, Accuracy: 5.570652484893799%, Test Loss: 3.454742670059204, Test Accuracy: 5.478332042694092%\n",
      "Epoch 9, Loss: 3.422560930252075, Accuracy: 5.3532609939575195%, Test Loss: 3.451803207397461, Test Accuracy: 5.451076507568359%\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # Reset the metrics at the start of the next epoch\n",
    "    train_loss2.reset_states()\n",
    "    train_accuracy2.reset_states()\n",
    "    test_loss2.reset_states()\n",
    "    test_accuracy2.reset_states()\n",
    "\n",
    "    for train_images, train_labels in train_gen2:\n",
    "        train_step2(train_images, train_labels)\n",
    "\n",
    "    for test_images, test_labels in test_gen2:\n",
    "        test_step2(test_images, test_labels)\n",
    "    if epoch % 1 == 0:\n",
    "        print(\n",
    "          f'Epoch {epoch}, '\n",
    "          f'Loss: {train_loss2.result()}, '\n",
    "          f'Accuracy: {train_accuracy2.result() * 100}%, '\n",
    "          f'Test Loss: {test_loss2.result()}, '\n",
    "          f'Test Accuracy: {test_accuracy2.result() * 100}%'\n",
    "      )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
